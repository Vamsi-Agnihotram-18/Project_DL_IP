{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import cnn modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D   #adding convolution layer : Cl for feature mapping \n",
    "from keras.layers import MaxPooling2D  # to extract the exact pooling\n",
    "from keras.layers import Flatten # multi to single dimentional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#cnn\n",
    "# 2 convolution layers and 2 max pooled , flattening\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,3, input_shape = (64,64,3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(32,3,3, input_shape = (64,64,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"random_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"random_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3, kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#ann\n",
    "# 2 hidden layers , 1 o/p layer\n",
    "model.add(Dense(output_dim=80,activation = 'relu', init='random_uniform'))\n",
    "model.add(Dense(output_dim=80,activation = 'relu', init='random_uniform'))\n",
    "\n",
    "model.add(Dense(output_dim=3 ,activation = 'softmax', init='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss= 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2 , zoom_range = 0.2, horizontal_flip = True) #to the images we apply few geometrical transformations to avoid over fitting\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 3 classes.\n",
      "Found 135 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'D:/project/dataset/train_data', target_size = (64,64),  batch_size = 32, class_mode = 'categorical')\n",
    "x_test = train_datagen.flow_from_directory(r'D:/project/dataset/test_data', target_size = (64,64),  batch_size = 32, class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kranthi': 0, 'pranav': 1, 'vamsi': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)  # print class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, validation_data=<keras.pre..., steps_per_epoch=9, validation_steps=135)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 1.0868 - accuracy: 0.3357 - val_loss: 1.0920 - val_accuracy: 0.3347\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.9703 - accuracy: 0.5000 - val_loss: 0.7743 - val_accuracy: 0.9767\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6683 - accuracy: 0.8453 - val_loss: 0.4998 - val_accuracy: 0.7942\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.3239 - accuracy: 0.9340 - val_loss: 0.2088 - val_accuracy: 0.8055\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1589 - accuracy: 0.9532 - val_loss: 0.0295 - val_accuracy: 0.9992\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1127 - accuracy: 0.9717 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0622 - accuracy: 0.9826 - val_loss: 0.0148 - val_accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.0297 - val_accuracy: 0.9879\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0474 - accuracy: 0.9823 - val_loss: 0.0495 - val_accuracy: 0.9975\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0233 - accuracy: 0.9965 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 4.7788e-04 - val_accuracy: 0.9997\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.7833e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.1775e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 12s 1s/step - loss: 9.3037e-04 - accuracy: 1.0000 - val_loss: 2.0425e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 11s 1s/step - loss: 8.8025e-04 - accuracy: 1.0000 - val_loss: 4.8417e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14d95f9cb88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, samples_per_epoch = 315, epochs = 20, validation_data = x_test, nb_val_samples = 135) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vamsimodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"vamsimodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "Data Found\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(r\"haarcascade_frontalface_default.xml\")\n",
    "# Defining a function that will do the detections\n",
    "def detect1(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces: # x , y co-ordinates of the face start , width , height .\n",
    "        print (\"Number of faces detected: \" + str(faces.shape[0]))\n",
    "        print(\"Data Found\")\n",
    "        cv2.putText(frame, \"Number of faces detected: \" + str(faces.shape[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        newframe_color = frame[y:y+h, x:x+w]\n",
    "        global i\n",
    "        FaceFileName = r\"D:\\project\\dataset/input\" + \".jpg\"\n",
    "        cv2.imwrite(FaceFileName, newframe_color)\n",
    "        i = i+1\n",
    "    return frame\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "i = 0\n",
    "capture = cv2.VideoCapture(0)\n",
    "while (i<1):\n",
    "    ret,frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect1(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('vamsimodel.h5')\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img=resize(frame,(64,64))\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img=img/255.0\n",
    "        prediction=model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction_class=model.predict_classes(img)\n",
    "        print(prediction_class)\n",
    "        num=int(prediction_class)\n",
    "        list1[num]=list1[num]+1\n",
    "        print(list1)\n",
    "    except AttributeError:\n",
    "        print('shape not found')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9994409e-01 1.2747824e-05 4.3135948e-05]]\n",
      "[0]\n",
      "[2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'D:\\project\\dataset\\input.jpg')\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
